# 开启本地模式

hive默认会在集群上进行执行，在开发环境可以开启本地模式，会大大加快SQL的执行速度。参数`hive.exec.mode.local.auto`控制是否会自动决定任务是否在本地执行。默认是false。当该值设置为true后，hive会根据几个参数来决定是否使用本地模式。

* hive.exec.mode.local.auto.inputbytes.max : 使用本地模式的文件的最大的大小，默认是134217728，即128MB。
* hive.exec.mode.local.auto.input.files.max : 默认是4。When Configuration Properties#hive.exec.mode.local.auto is true, the number of tasks should be less than this for local mode.

执行`select count(1) from person`会进行mapreduce计算，没有开启自动本地模式前，执行花费的时间如下。

```text
hive> select count(1) from person;
Query ID = root_20200718153128_79b9c373-9e93-44a9-876c-30426721690d
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1595085469683_0001, Tracking URL = http://hadoop-master:8088/proxy/application_1595085469683_0001/
Kill Command = /opt/hadoop-3.2.1/bin/mapred job  -kill job_1595085469683_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-07-18 15:31:40,913 Stage-1 map = 0%,  reduce = 0%
2020-07-18 15:31:46,182 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.14 sec
2020-07-18 15:31:51,455 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.38 sec
MapReduce Total cumulative CPU time: 4 seconds 380 msec
Ended Job = job_1595085469683_0001
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.38 sec   HDFS Read: 17171 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 4 seconds 380 msec
OK
50
Time taken: 24.458 seconds, Fetched: 1 row(s)
```

然后开启自动本地模式。

```text
hive> set hive.exec.mode.local.auto=true;
hive> set hive.exec.mode.local.auto;
hive.exec.mode.local.auto=true
```

开启了自动的本地模式后花费的时间如下。

```text
hive> select count(1) from person;
Query ID = root_20200718154103_f5ef6b5a-b504-4e28-802e-1eb665bc79d5
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Cannot run job locally: Number of Input Files (= 6) is larger than hive.exec.mode.local.auto.input.files.max(= 4)
Starting Job = job_1595085469683_0003, Tracking URL = http://hadoop-master:8088/proxy/application_1595085469683_0003/
Kill Command = /opt/hadoop-3.2.1/bin/mapred job  -kill job_1595085469683_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-07-18 15:41:10,593 Stage-1 map = 0%,  reduce = 0%
2020-07-18 15:41:14,761 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2020-07-18 15:41:19,925 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.01 sec
MapReduce Total cumulative CPU time: 4 seconds 10 msec
Ended Job = job_1595085469683_0003
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.01 sec   HDFS Read: 17176 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 4 seconds 10 msec
OK
50
Time taken: 18.759 seconds, Fetched: 1 row(s)
```

## 参考文档

* [https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties](https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties)
